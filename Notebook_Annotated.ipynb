{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de7eb03c",
   "metadata": {},
   "source": [
    "Step 1: Understand the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a606fb",
   "metadata": {},
   "source": [
    "Train.csv – Contains image IDs and their corresponding labels (0 = not affected, 1 = affected).\n",
    "\n",
    "Test.csv – Contains image IDs for which you need to predict labels.\n",
    "\n",
    "SampleSubmission.csv – Shows the expected format for your final submission.\n",
    "\n",
    "Images.zip – Contains all the image files (likely for both training and test data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d520849",
   "metadata": {},
   "source": [
    "### Step 2: Install Required Packages\n",
    "Install necessary Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58674582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.17.3; python_version >= \"3.8\" in c:\\users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages (from opencv-python) (1.23.0)\n",
      "Requirement already satisfied: numpy==1.23 in c:\\users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages (1.23.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install numpy==1.23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33d34b2",
   "metadata": {},
   "source": [
    "### Step 3: Import Libraries\n",
    "Import all required libraries for data processing, modeling, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7989ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7931d84f",
   "metadata": {},
   "source": [
    "### Step 4: Load Training Data\n",
    "Load the training CSV file which contains image IDs and their corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ed9e681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Image_id', 'Label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"Data/Train.csv\")\n",
    "print(train_df.columns)  # Fix column case sensitivity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65c31d2",
   "metadata": {},
   "source": [
    "### Step 5: Preprocess Images\n",
    "Load and preprocess images from the directory. Resize them and convert to arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d46c6ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"Data/Images\"\n",
    "image_size = (128, 128)  # You can change this depending on device limitations\n",
    "\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "for i, row in train_df.iterrows():\n",
    "    image_id = row['Image_id']  # Already has .jpg\n",
    "    label = row['Label']\n",
    "    \n",
    "    image_path = os.path.join(image_folder, image_id)\n",
    "\n",
    "    if os.path.exists(image_path):\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.resize(img, image_size)\n",
    "        train_images.append(img)\n",
    "        train_labels.append(label)\n",
    "    else:\n",
    "        print(f\"Missing image: {image_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8dca30",
   "metadata": {},
   "source": [
    "### Step 6: Normalize Image Data\n",
    "Normalize image pixel values for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4508ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.array(train_images) / 255.0  # Normalize pixel values\n",
    "train_labels = np.array(train_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca8c5a",
   "metadata": {},
   "source": [
    "### Step 7: Split Data\n",
    "Split the data into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a87067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_images, train_labels, test_size=0.2, stratify=train_labels, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2895772c",
   "metadata": {},
   "source": [
    "### Step 8: Define the Model\n",
    "Build a CNN model using Keras Sequential API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7151fed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               7372928   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 7,392,449\n",
      "Trainable params: 7,392,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4119cb",
   "metadata": {},
   "source": [
    "### Step 9: Data Augmentation & Training\n",
    "Apply data augmentation and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77ce7ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 8s 204ms/step - loss: 0.6894 - auc: 0.6372 - val_loss: 0.5802 - val_auc: 0.8528\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 8s 191ms/step - loss: 0.5374 - auc: 0.8094 - val_loss: 0.4143 - val_auc: 0.8963\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 8s 185ms/step - loss: 0.4342 - auc: 0.8849 - val_loss: 0.3669 - val_auc: 0.9158\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 8s 190ms/step - loss: 0.4211 - auc: 0.8939 - val_loss: 0.3555 - val_auc: 0.9223\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 7s 178ms/step - loss: 0.4299 - auc: 0.8870 - val_loss: 0.3125 - val_auc: 0.9399\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 7s 176ms/step - loss: 0.3618 - auc: 0.9207 - val_loss: 0.3449 - val_auc: 0.9508\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 7s 179ms/step - loss: 0.3334 - auc: 0.9339 - val_loss: 0.3837 - val_auc: 0.9534\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 7s 183ms/step - loss: 0.3119 - auc: 0.9410 - val_loss: 0.2608 - val_auc: 0.9587\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 8s 188ms/step - loss: 0.3009 - auc: 0.9450 - val_loss: 0.3627 - val_auc: 0.9440\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 7s 177ms/step - loss: 0.2827 - auc: 0.9525 - val_loss: 0.3468 - val_auc: 0.9443\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(horizontal_flip=True, rotation_range=20, zoom_range=0.2)\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=32),\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0d01c2",
   "metadata": {},
   "source": [
    "### Step 10: Evaluate the Model\n",
    "Evaluate model performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c483d11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 41ms/step - loss: 0.3468 - auc: 0.9443\n",
      "Validation AUC: 0.9443\n"
     ]
    }
   ],
   "source": [
    "loss, auc = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation AUC: {auc:.4f}\")\n",
    "\n",
    "model.save(\"fall_armyworm_cnn.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e906a",
   "metadata": {},
   "source": [
    "### Step 11: Save the Model\n",
    "Save the trained model for future inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87f8cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Data/my_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75ef689",
   "metadata": {},
   "source": [
    "### Step 12: Load Test Data and Model\n",
    "Prepare the environment for testing and load the saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d92ce8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission.csv with columns ['Image_ID', 'Target']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Parameters\n",
    "img_height = 128  # your image size\n",
    "img_width = 128\n",
    "batch_size = 32\n",
    "\n",
    "# Paths\n",
    "test_csv_path = \"Data\\Test.csv\"\n",
    "test_images_folder = \"Data\\Images\"  # update if needed\n",
    "\n",
    "# Load test IDs\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "image_ids = test_df['Image_id'].tolist()  # this column in your Test.csv\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)  # or decode_png if needed\n",
    "    img = tf.image.resize(img, [img_height, img_width])\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "# Full image paths\n",
    "test_image_paths = [os.path.join(test_images_folder, img_id) for img_id in image_ids]\n",
    "\n",
    "# Dataset\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(test_image_paths)\n",
    "test_ds = test_ds.map(load_and_preprocess_image).batch(batch_size)\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model('Data/my_model.h5')\n",
    "\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(test_ds)\n",
    "\n",
    "# Prepare submission dataframe with correct columns and formatting\n",
    "submission_df = pd.DataFrame({\n",
    "    'Image_ID': image_ids,\n",
    "    'Target': predictions.flatten()\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"Saved submission.csv with columns ['Image_ID', 'Target']\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a968333",
   "metadata": {},
   "source": [
    "### Step 13: Visualize Predictions\n",
    "Display prediction results using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb853950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAFgCAYAAAC2QAPxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAAsTAAALEwEAmpwYAAAo+0lEQVR4nO3deZhkdX33/fdHQFAHw6YjMsi4oE9wgTCjkrhkBjUqRlGjgMF9QXOrMYZERaOQoLfmMWPUxxWXiBuj4kYUbxdkQHMHdRjZjZEoCCMOi2yDyvp9/jinoWh6qenuquo+/X5dV11ddeos3/OrnqlP/87vnJOqQpIkqUvuNOoCJEmS5poBR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5pHknwiyVvb549J8tMZrudDSd48t9XNrd59ncGyRyX59BTvn5tk1fh5k9wnyeYkW81kuzOR5BtJXjBH67rd70SSC5I8fi7W3a7v1naTFjoDjrSF2i+V37VflJvaL+olc72dqvpeVT2oj3pemOT745Z9RVUdPdc1tWHhxnbfr0ryf5P88VxvZ7aq6sFVtW6C6b+sqiVVdTNAknVJXjrT7SSpJNe17XFFkpOSHDxum0+uqmP7XNcDppqn39+JfkwUMCdrN2khMuBIM/PUqloC7AusBP5h/AxJth56VcPxuXbf7wF8H/hSkoyfaZi9JCO2d9seDwI+AbwvyZFzvZEO/z5JA2HAkWahqjYC3wAeArf+Ff7KJD8DftZO+/MkZ/T0eDxsbPkkf5RkQ5Jrk3wO2K7nvVVJLu55vXuSLyW5rO0teF+SPwQ+BPzxWK9KO+/t/jpP8rIk5yf5TZITkty7571K8ookP2trfP9EgWWCfb8ROBa4F7Bzu80PJjkxyXXA6iR/2PaSXNUe/njauNXskuTb7f6fkmSPnrrek+SiJNckOT3JY8Ytu12Sz7XLbkiyd8+yEx66SbK83d+tk7wNeAxNINnctuf7k6wZt8wJSV7bR3tcXlWfAv4KOCLJzu3yt/YSJXlAu59XJ7m8/cxJcmq7mjPbWg4e+/yTvD7Jr4F/G/870Xp4kvOSXJnk35Js167zDj17Y71ESQ4DDgVe127v38e3W5Jtk7w7ya/ax7uTbNu+N1bb4UkuTXJJkhdN10bSMBlwpFlIsjtwAPDjnslPBx4J7JXkj4CPAy8HdgY+DJzQfnncGfgK8ClgJ+ALwF9Msp2tgK8BFwLLgd2AtVX1E+AVwH+2h152mGDZ/YG3AwcBu7brWDtutj8HHg48rJ3viX3s+7bAC4GLqurydvJfAm8Dtgd+APw78C3gnsCrgc8k6T3EcihwNLALcAbwmZ73fgTsQ9M2nwW+MPbl3TqQps3G3v9Kkm2mq3tMVb0J+B7wqrbtXkUT2J6T5E7tPu4CPL5df7++CmwNPGKC946maY8dgWXA/9fW8tj2/b3bWj7Xvr5Xu397AIdNsr1DaT6v+wMPZILexPGq6hiatv5/2+09dYLZ3gTsR/MZ7N3uT++67wX8Ac3v4kuA9yfZcbptS8NiwJFm5ittb8n3gVOA/93z3tur6jdV9TuaL6UPV9UPqurmdizG9TRfHPsB2wDvrqobq+p4mi/1iTwCuDfw91V1XVX9vqq+P8m84x0KfLyqNlTV9cARND0+y3vmeUdVXVVVvwROpvlSm8xB7b5fBKwAntHz3ler6j+q6pZ2HUvadd9QVd+lCWnP6Zn/61V1alvXm9q6dgeoqk9X1RVVdVNVrQG2pTkMNOb0qjq+7Ul6F03v1359tsmEquqHwNXA49pJhwDrqmrTFqzjRuBymmAy3o00YeXefX6GtwBHVtX17e/TRN5XVRdV1W9owuVzJplvSx0K/FNVXVpVlwH/CDyv5/0b2/dvrKoTgc3c/vORRsqAI83M06tqh6rao6r+17gvn4t6nu8BHN4eormqDQa704SVewMb6/Z3vL1wku3tDlxYVTfNoNZ79663qjYDV9D85T3m1z3Pf0sTTCbz+Xbf71lV+1fV6T3v9e77vWl6d27pmXbhuO3eOn9b12/a5Ujyd0l+0h7OuYqmt2CXSZa9Bbh4bNlZOhZ4bvv8uTQ9bH1re5HuQbMv470OCPDD9pDdi6dZ3WVV9ftp5ult8wuZmzaAcb83E6z7inG/j9P93khDZcCR5l5vYLkIeFsbCMYed62q44BLgN3GjXe5zyTrvAi4TyYeaFoTTOv1K5qgBUCSu9EcLts43Y7MQG8tvwJ2Hzvc07rPuO3u3lPXEppej1+1421eR3O4bMf20NvVNOFgomXvRHPI51ezqHfMp4ED2zE9f0hzGHFLHAjcBPzwDhur+nVVvayq7k1z2PIDmfrMqek+W+hpB5r2HWuD64C7jr2R5F5buO7b/d6MW7c07xlwpMH6CPCKJI9M425JnpJke+A/ab4I/zrJNkmeycTjNqD5srwEeEe7ju2SPKp9bxOwrB3TM5HjgBcl2acdN/O/gR9U1QVztI+T+QHNX/Wva/dvFfBUbj/+54Akj25rPxo4raouohnDcxNwGbB1krcAdx+3/hVJntmGvr+hOfR32hbWuAm4X++EqrqY5lDhp4AvTnFo6HaS7JTkUOD9wD9X1RUTzPPsJMval1fShIyxHq471NKnVyZZlmQnmsN8Y+N3zgQe3H7u2wFHjVtuuu0dB/xDknu0Y5HeQhP+pAXBgCMNUFWtB14GvI/mC+18moG5VNUNwDPb178BDga+NMl6bqYJBw8AfklzOGbseivfBc4Ffp3k8gmW/Q7wZuCLNCHp/jRjSwaq3b+nAk+mGZPyAeD5VfVfPbN9FjiSZv9XcNuhoW8C/wf4b5pDI7/n9odioBnMezBNuz4PeGY7/mVLvAd4VnsG0nt7ph8LPJT+Dk+dmWQzzWf7UuC1VfWWSeZ9OPCDdv4TgNdU1c/b944Cjm0PZR60BfvwWZqByz8H/gd4K0BV/TfwT8B3aM7oGz/e52M0A+GvSvKVCdb7VmA9cBZwNrBhbN3SQpDbH/6XJCV5LE1vxR7lf5LSgmQPjiT1aAcJvwb4qOFGWrgMOJLUSnPhxKtorhf07pEWI2lWPEQlSZI6xx4cSZLUOQv65m277LJLLV++fGDrv+6667jb3e42sPXrjmzz0bDdh882Hw3bffgG3eann3765VV1j/HTF3TAWb58OevXrx/Y+tetW8eqVasGtn7dkW0+Grb78Nnmo2G7D9+g2zzJhFeA9xCVJEnqHAOOJEnqHAOOJEnqHAOOJEnqHAOOJEnqHAOOJEnqHAOOJEnqHAOOJEnqHAOOJEnqHAOOJEnqHAOOJEnqHAOOJEnqHAPOFM46+2ySTPlYtsfyUZcpSZLGWdB3Ex+0G2+4gbdvuGzKeY7Y9w53aJckSSNmD44kSeocA44kSeocA44kSeocA44kSeocA44kSeocA44kSeocA44kSeocA44kSeocA44kSeocA44kSeocA44kSeocA44kSeocA44kSeocA44kSeocA44kSeocA44kSeocA44kSeocA44kSeocA44kSeocA44kSeocA44kSeocA44kSeocA44kSeqcgQWcJLsnOTnJeUnOTfKadvpRSTYmOaN9HNCzzBFJzk/y0yRPHFRtkiSp27Ye4LpvAg6vqg1JtgdOT/Lt9r1/rap/6Z05yV7AIcCDgXsD30nywKq6eYA1SpKkDhpYD05VXVJVG9rn1wI/AXabYpEDgbVVdX1V/QI4H3jEoOqTJEndlaoa/EaS5cCpwEOAvwVeCFwDrKfp5bkyyfuA06rq0+0yHwO+UVXHj1vXYcBhAEuXLl2xdu3agdW9adMm6u47TznPxvPOZMWKFQOrYbHZvHkzS5YsGXUZi47tPny2+WjY7sM36DZfvXr16VW1cvz0QR6iAiDJEuCLwN9U1TVJPggcDVT7cw3w4n7XV1XHAMcArFy5slatWjXnNY9Zs2YNN+7/uCnnOeKAJzCMkLhYrFu3jkF+ppqY7T58tvlo2O7DN6o2H+hZVEm2oQk3n6mqLwFU1aaqurmqbgE+wm2HoTYCu/csvqydJkmStEUGeRZVgI8BP6mqd/VM37VntmcA57TPTwAOSbJtkvsCewI/HFR9kiSpuwZ5iOpRwPOAs5Oc0U57I/CcJPvQHKK6AHg5QFWdm+TzwHk0Z2C90jOoJEnSTAws4FTV94FM8NaJUyzzNuBtg6pJkiQtDl7JWJIkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5Ikdc7AAk6S3ZOcnOS8JOcmeU07fack307ys/bnju30JHlvkvOTnJVk30HVJkmSum2QPTg3AYdX1V7AfsArk+wFvAE4qar2BE5qXwM8GdizfRwGfHCAtUmSpA4bWMCpqkuqakP7/FrgJ8BuwIHAse1sxwJPb58fCHyyGqcBOyTZdVD1SZKk7kpVDX4jyXLgVOAhwC+raod2eoArq2qHJF8D3lFV32/fOwl4fVWtH7euw2h6eFi6dOmKtWvXDqzuTZs2UXffecp5Np53JitWrBhYDYvN5s2bWbJkyajLWHRs9+GzzUfDdh++Qbf56tWrT6+qleOnbz2wLbaSLAG+CPxNVV3TZJpGVVWSLUpYVXUMcAzAypUra9WqVXNY7e2tWbOGG/d/3JTzHHHAExhGSFws1q1bxyA/U03Mdh8+23w0bPfhG1WbD/QsqiTb0ISbz1TVl9rJm8YOPbU/L22nbwR271l8WTtNkiRpiwzyLKoAHwN+UlXv6nnrBOAF7fMXAF/tmf789myq/YCrq+qSQdUnSZK6a5CHqB4FPA84O8kZ7bQ3Au8APp/kJcCFwEHteycCBwDnA78FXjTA2iRJUocNLOC0g4Uzydt3GNhSzUCWVw6qHkmStHh4JWNJktQ5BhxJktQ5BhxJktQ5BhxJktQ50wacJM9Osn37/B+SfMkbYUqSpPmsnx6cN1fVtUkeDTye5to23ghTkiTNW/0EnJvbn08BjqmqrwN3HlxJkiRJs9NPwNmY5MPAwcCJSbbtczlJkqSR6CeoHAR8E3hiVV0F7AT8/SCLkiRJmo1pA05V/ZbmhpiPbifdBPxskEVJkiTNRj9nUR0JvB44op20DfDpQRYlSZI0G/0conoG8DTgOoCq+hWw/SCLkiRJmo1+As4N7Y0wCyDJ3QZbkiRJ0uz0E3A+355FtUOSlwHfAT4y2LIkSZJmbuvpZqiqf0nyBOAa4EHAW6rq2wOvTJIkaYamDTgAbaAx1EiSpAVh2oCT5Fra8Tc9rgbWA4dX1c8HUZgkSdJM9dOD827gYuCzQIBDgPsDG4CPA6sGVJskSdKM9DPI+GlV9eGquraqrqmqY2iuavw5YMcB1ydJkrTF+gk4v01yUJI7tY+DgN+3740/dCVJkjRy/QScQ4Hn0dyuYVP7/LlJ7gK8aoC1SZIkzUg/p4n/HHjqJG9/f27LkSRJmr1+zqLaDngJ8GBgu7HpVfXiAdYlSZI0Y/0covoUcC/gicApwDLg2kEWJUmSNBv9BJwHVNWbgeuq6ljgKcAjB1uWJEnSzPUTcG5sf16V5CHAHwD3HFxJkiRJs9PPhf6OSbIj8GbgBGAJ8JaBViVJkjQL0/bgVNVHq+rKqjqlqu5XVfesqg8NozhJkjR/LdtjOUmmfJx19tkjqa2fs6h2AJ4PLO+dv6r+emBVSZKkeW/jLy/k7Rsum3KeG7977JCqub1+DlGdCJwGnA3cMthyJEmSZq+fgLNdVf3twCuRJEmaI31dByfJy5LsmmSnscfAK5MkSZqhfnpwbgDeCbyJ226uWcD9BlWUJEnSbPQTcA6nudjf5YMuRpIkaS70c4jqfOC3gy5EkiRprvTTg3MdcEaSk4HrxyZ6mrgkSZqv+gk4X2kfkiRJC8K0Aae9waYkSdKCMWnASXI2t501dQdV9bCBVCRJkjRLU/Xg/PnQqpAkSZpDkwacqrpwmIVIkiTNlX5OE5+RJB9PcmmSc3qmHZVkY5Iz2scBPe8dkeT8JD9N8sRB1SVJkrpvYAEH+ATwpAmm/2tV7dM+TgRIshdwCPDgdpkPJNlqgLVJkqQOmzTgJDmp/fnPM1lxVZ0K/KbP2Q8E1lbV9VX1C5qLCz5iJtuVJElK1cQnSiU5D3gp8DHgL4H0vl9VG6ZdebIc+FpVPaR9fRTwQuAaYD1weFVdmeR9wGlV9el2vo8B36iq4ydY52HAYQBLly5dsXbt2n72c0Y2bdpE3X3nKefZeN6ZrFixYmA1LDabN29myZIloy5j0bHdh882Hw3bfW6dfvrp7LbX3lPOk2uuYOnSpQOrYfXq1adX1crx06c6i+otwJuBZcC7xr1XwP4zqOODwNHt8kcDa4AXb8kKquoY4BiAlStX1qpVq2ZQRn/WrFnDjfs/bsp5jjjgCUwWErXl1q1bxyA/U03Mdh8+23w0bPe5tXr1at6+4bIp59nmvGM5+OCDh1TRbaY6i+p44Pgkb66qo+diY1W1aex5ko8AX2tfbgR275l1WTtNkiRpi007yLiqjk7ytCT/0j5mfH2cJLv2vHwGMHaG1QnAIUm2TXJfYE/ghzPdjiRJWtymvVVDkrfTDPj9TDvpNUn+pKreOM1yxwGrgF2SXAwcCaxKsg/NIaoLgJcDVNW5ST4PnAfcBLyyqm6eyQ5JkiT1c7PNpwD7VNUtAEmOBX4MTBlwquo5E0z+2BTzvw14Wx/1SJIkTanf6+Ds0PP8DwZQhyRJ0pzppwfn7cCPk5xMc6r4Y4E3DLQqSZKkWZg24FTVcUnWAQ9vJ72+qn490KokSZJmoZ8eHKrqEpoznSRJkua9Qd6LSpIkaSQMOJIkqXOmDDhJtkryX8MqRpIkaS5MGXDai+39NMl9hlSPJEnSrPUzyHhH4NwkPwSuG5tYVU8bWFWSJEmz0E/AefPAq5AkSZpD/VwH55QkewB7VtV3ktwV2GrwpUmSJM3MtGdRJXkZcDzw4XbSbsBXBliTJEnSrPRzmvgrgUcB1wBU1c+Aew6yKEmSpNnoJ+BcX1U3jL1IsjVQgytJkiRpdvoJOKckeSNwlyRPAL4A/Ptgy5IkSZq5fgLOG4DLgLOBlwMnAv8wyKIkSZJmo5+zqG5JcizwA5pDUz+tKg9RSZKkeWvagJPkKcCHgP8BAtw3ycur6huDLk6SJGkm+rnQ3xpgdVWdD5Dk/sDXAQOOJEmal/oZg3PtWLhp/Ry4dkD1SJIkzdqkPThJntk+XZ/kRODzNGNwng38aAi1SZIkzchUh6ie2vN8E/Cn7fPLgLsMrCJJkqRZmjTgVNWLhlmIJEnSXOnnLKr7Aq8GlvfOX1VPG1xZkiRJM9fPWVRfAT5Gc/XiWwZajSRJ0hzoJ+D8vqreO/BKJEmS5kg/Aec9SY4EvgVcPzaxqjYMrCpJkqRZ6CfgPBR4HrA/tx2iqva1JEnSvNNPwHk2cL+qumHQxUiSJM2Ffq5kfA6ww4DrkCRJmjP99ODsAPxXkh9x+zE4niYuSZLmpX4CzpEDr0KSJGkOTRtwquqUYRQiSZI0V/q5kvG1NGdNAdwZ2Aa4rqruPsjCJEmSZqqfHpztx54nCXAgsN8gi5IkSZqNfs6iulU1vgI8cTDlSJIkzV4/h6ie2fPyTsBK4PcDq0iSJGmW+jmL6qk9z28CLqA5TCVJkjQv9TMG50XDKESSJGmuTBpwkrxliuWqqo4eQD2SJEmzNlUPznUTTLsb8BJgZ8CAI0mS5qVJz6KqqjVjD+AY4C7Ai4C1wP2mW3GSjye5NMk5PdN2SvLtJD9rf+7YTk+S9yY5P8lZSfad9Z5JkqRFa8rTxNtA8lbgLJrenn2r6vVVdWkf6/4E8KRx094AnFRVewInta8Bngzs2T4OAz7Y9x5IkiSNM2nASfJO4EfAtcBDq+qoqrqy3xVX1anAb8ZNPhA4tn1+LPD0numfbK+zcxqwQ5Jd+92WJElSr1TVxG8kt9DcPfwmbrtVA0BoBhlPe6uGJMuBr1XVQ9rXV1XVDu3zAFdW1Q5Jvga8o6q+3753EvD6qlo/wToPo+nlYenSpSvWrl3b565uuU2bNlF333nKeTaedyYrVqwYWA2LzebNm1myZMmoy1h0bPfhs81Hw3afW6effjq77bX3lPPkmitYunTpwGpYvXr16VW1cvz0SQcZV9UWXeV4S1VVJZk4XU293DE0Y4JYuXJlrVq1aq5Lu9WaNWu4cf/HTTnPEQc8gclCorbcunXrGORnqonZ7sNnm4+G7T63Vq9ezds3XDblPNucdywHH3zwkCq6zUBDzAQ2jR16an+OjeXZCOzeM9+ydpokSdIWG3bAOQF4Qfv8BcBXe6Y/vz2baj/g6qq6ZMi1SZKkjujnVg0zkuQ4YBWwS5KLgSOBdwCfT/IS4ELgoHb2E4EDgPOB39Kcji5JkjQjAws4VfWcSd66w6CWagaxvHJQtUiSpMVl2IeoJEmSBs6AI0mSOseAI0mSOseAI0mSOseAI0mSOseAI0mSOseAI0mSOseAM0tb33lbkkz5WLbH8lGXKUnSojKwC/0tFjfdcP20Nxo7Yt97DKkaSZIE9uBIkqQOMuBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTOMeBIkqTO2XoUG01yAXAtcDNwU1WtTLIT8DlgOXABcFBVXTmK+iRJ0sI2yh6c1VW1T1WtbF+/ATipqvYETmpfS5IkbbH5dIjqQODY9vmxwNNHV4okSVrIUlXD32jyC+BKoIAPV9UxSa6qqh3a9wNcOfZ63LKHAYcBLF26dMXatWsHVuemTZuou+885TwbzzuT3fbae9p5VqxYMZelddbmzZtZsmTJqMtYdGz34bPNR8N2799ZZ5/NjTfcMO18030H5porWLp06VyVdQerV68+vedo0G3bHVHA2a2qNia5J/Bt4NXACb2BJsmVVbXjVOtZuXJlrV+/fmB1rlmzhhv3f8GU8xyx7z14+4bLppznzfst46Ybrp92e7vdZw8uvvCCLSmxc9atW8eqVatGXcaiY7sPn20+GrZ7/5JM+/3Wz3fgNt89lsMPP3wuS7udJBMGnJEMMq6qje3PS5N8GXgEsCnJrlV1SZJdgUtHUdsg3HTD9dP+AkDziyJJkmZv6GNwktwtyfZjz4E/A84BTgDGukteAHx12LVJkqRuGEUPzlLgy80wG7YGPltV/yfJj4DPJ3kJcCFw0AhqkyRJHTD0gFNVPwfuMCKpqq4AHjfseiRJUvfMp9PEJUmS5oQBR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BZx7Z+s7bkmTKx7I9lo+6TEmS5r2R3ItKE+vnnlXer0qSpOnZgyNJkjrHgCNJkjrHgCNJkjrHgCNJkjrHgCNJkjrHgCNJkjrHgCNJ0iKybI/l015zLcmoy5w1r4MjSdIisvGXF057zTVY+NddswdHkiR1jgFHkiR1jgFHkiR1jgFHkqSO6GcA8WLhIOMFZuyO41PZ7T57cPGFFwynIEnSvNHPAOKFPni4XwacBcY7jkuSND0PUS1i/XRlLttj+ajLlCRpi9mDs4j105X55v2WeUhMkrTgGHA0JQ+JSdLoLdtjORt/eeGoy1hQDDiSJM1zi+Xqw3PJgNNB/ZxpJUlSlxlwOqifw0pg0pckdZdnUUmSpM4x4EhzxNPuJWn+8BCVhqafswDe8973smrVquEUNMe8gqgkzR8GHA1NPwHgppM/6XV3JEmzZsDRvFJV9oJIi0g/Pbtd/6PGa9wMhgFHs+Zp6ZJmaq4O7fYbEoZ9GLzfuvzDbu4ZcDRrwz4tvd9ANZd/9fkX1sJmL0H/v8MLtR36vRDejd89dk62tyX/JxheRsOAowVnFNf5cQDx/DTsL5mFHBK8Eu7csj3nPwOONESj6H2aj+aqR2XYXzKj+FKz92n47LHtBgOOOqufMDHsL4Z+e5/m6i7u83Vcgj1i/VuobTWXIWEux/mNXZNqOguxzXV7Bhx11kK+E/pc1T6fxyVo7szHgf5z2ds1l/+WPVNz8TDgaFGbj18M/Rr2X7XDPmQ07M9mLrfXz7rmstds2GHeIKuFYN4FnCRPAt4DbAV8tKreMeKS1GEL+cakXf+rdthf2nO5vX7WNVe9ZqOwUA+baXGZVwEnyVbA+4EnABcDP0pyQlWdN9rKJC3k3i71z89ZXTGvAg7wCOD8qvo5QJK1wIGAAUcasYU8pmk+6new67D5OasrUlWjruFWSZ4FPKmqXtq+fh7wyKp6Vc88hwGHtS8fBPx0gCXtAlw+wPXrjmzz0bDdh882Hw3bffgG3eZ7VNUdUvd868GZVlUdAxwzjG0lWV9VK4exLTVs89Gw3YfPNh8N2334RtXmdxr2BqexEdi95/WydpokSVLf5lvA+RGwZ5L7JrkzcAhwwohrkiRJC8y8OkRVVTcleRXwTZrTxD9eVeeOsKShHArT7djmo2G7D59tPhq2+/CNpM3n1SBjSZKkuTDfDlFJkiTNmgFHkiR1zqIPOEmelOSnSc5P8oYJ3t82yefa93+QZPkIyuycPtr9b5Ocl+SsJCcl2WMUdXbJdG3eM99fJKkknko7B/pp9yQHtb/v5yb57LBr7Jo+/n+5T5KTk/y4/T/mgFHU2SVJPp7k0iTnTPJ+kry3/UzOSrLvwIuqqkX7oBnI/D/A/YA7A2cCe42b538BH2qfHwJ8btR1L/RHn+2+Grhr+/yvbPfBt3k73/bAqcBpwMpR173QH33+ru8J/BjYsX19z1HXvZAffbb5McBftc/3Ai4Ydd0L/QE8FtgXOGeS9w8AvgEE2A/4waBrWuw9OLfeGqKqbgDGbg3R60Bg7K54xwOPy3y8vvrCMm27V9XJVfXb9uVpNNdE0sz187sOcDTwz8Dvh1lch/XT7i8D3l9VVwJU1aVDrrFr+mnzAu7ePv8D4FdDrK+TqupU4DdTzHIg8MlqnAbskGTXQda02APObsBFPa8vbqdNOE9V3QRcDew8lOq6q5927/USmuSvmZu2zdsu492r6uvDLKzj+vldfyDwwCT/keS0JE8aWnXd1E+bHwU8N8nFwInAq4dT2qK2pf/vz9q8ug6ONF6S5wIrgT8ddS1dluROwLuAF464lMVoa5rDVKtoeipPTfLQqrpqlEV13HOAT1TVmiR/DHwqyUOq6pZRF6a5s9h7cPq5NcSt8yTZmqY784qhVNddfd2SI8njgTcBT6uq64dUW1dN1+bbAw8B1iW5gOYY+QkONJ61fn7XLwZOqKobq+oXwH/TBB7NTD9t/hLg8wBV9Z/AdjQ3hNTgDP1WTIs94PRza4gTgBe0z58FfLfaEVOasWnbPckfAR+mCTeOSZi9Kdu8qq6uql2qanlVLacZ9/S0qlo/mnI7o5//Y75C03tDkl1oDln9fIg1dk0/bf5L4HEASf6QJuBcNtQqF58TgOe3Z1PtB1xdVZcMcoOL+hBVTXJriCT/BKyvqhOAj9F0X55PM4DqkNFV3A19tvs7gSXAF9ox3b+sqqeNrOgFrs821xzrs92/CfxZkvOAm4G/ryp7iWeozzY/HPhIktfSDDh+oX+4zk6S42iC+i7t2KYjgW0AqupDNGOdDgDOB34LvGjgNfmZSpKkrlnsh6gkSVIHGXAkSVLnGHAkSVLnGHAkSVLnGHAkSVLnGHCkeS7JzUnOSHJOki8kuess1vWJJM9qn380yV5TzLsqyZ/MYBsXtNdzmWj62e2dhL+V5F5bsM5VSb42R3W8Isnz2+cTtkeSN27Jttpl7pLklCR7t5/XGUl+k+QX7fPvbOk6+9zu8iR/2fP6oUk+MYhtSQuJAUea/35XVftU1UOAG4BX9L7ZXmF7i1XVS6vqvClmWQVsccCZxuqqehiwHrhdiGgvADbw/5Oq6kNV9ckJpve2xxYHHODFwJeq6sz289qH5uJmf9++fvx0K5jhZ7kcuDXgVNXZwLIk95nBuqTOMOBIC8v3gAe0PRrfS3ICcF6SrZK8M8mP2h6Sl8OtoeF9SX7a9iDcc2xFSdaN3YohyZOSbEhyZpKTkiynCVKvbXsfHpPkHkm+2G7jR0ke1S67c9sjc26SjwLpYz9ObfdjeVvbJ4FzgN3b/Tin7e05uGeZuyf5ejv/h8bCUJIPJlnfbv8fx23nde16fpjkAe38RyX5u/EFjbVHkncAd2n3+zNJ/inJ3/TM97Ykr5lgnw4FvjrZDid5S9tu5yQ5JmmuYNlu991J1gOvSfLw9jM8Y6wt2vkm/IyBdwCPaed/bTvt3/GipFrkDDjSAtH+df9k4Ox20r7Aa6rqgTT31rm6qh4OPBx4WZL7As8AHgTsBTyfCXpkktwD+AjwF1W1N/DsqroA+BDwr23vw/eA97SvHw78BfDRdhVHAt+vqgcDXwb66Tn485792BP4QLv8SmAfYG/g8cA7k+zazvcImrs+7wXcH3hmO/1NVbUSeBjwp0ke1rOdq6vqocD7gHf3URdV9QZu6zU7FPg4TduN3ZT0EODTvcukuSXA/dp2m8z7qurhbU/cXdo2GHPnqlpZVWuAfwNe3vYA3dwzz2Sf8RuA77X1/ms773rgMf3sr9RVi/pWDdICcZckZ7TPv0dz+5A/AX7Y3pwR4M+Ah42NJ6G5KeyewGOB46rqZuBXSb47wfr3A04dW1dV/WaSOh4P7NV2PEDTo7Kk3cYz22W/nuTKKfbl5CQ3A2cB/wDsAFxYVae17z+6p95NSU6h+TK/pt3fn8Otl4V/NHA8cFCSw2j+P9uVJgCd1a7vuJ6fY1/+W6SqLkhyRZr7oy0FfjzBrRR2Aa6aZlWrk7wOuCuwE3AuTU8LwOfa/doB2L69ASTAZ7ktCE32Gd8wwbYuBe49/d5J3WXAkea/37V/zd+qDRnX9U4CXl1V3xw33wFzWMedgP2q6vcT1NKv1VV1ec+yO3D7/ZjK+PvKVNuD8XfAw6vqynZw7XaTLDOb+9J8FHghcC+aHp3xfjduu7eTZDvgA8DKqrooyVHj5u+nDSb7jFdNMO92bU3SouUhKqkbvgn8VZJtAJI8MMndaMa6HNyO39gVWD3BsqcBj23DAkl2aqdfC2zfM9+3aA4R0c63T/v0VNpBrkmeDOw4i/34Xk+996DpHfph+94j0twh+k7AwcD3gbvThIOrkyylOYTX6+Cen/9J/24ca8vWl4En0fQmfXP8zFV1JbBVG2QmMjb98rbX61kTzVRVVwHXJnlkO6l3HM1kn/H4zwmaO5KfM0kt0qJgD47UDR+lOZtmQzt49TLg6TRfzPsD5wG/ZIIv+aq6rD3E86U2PFwKPIHm8MnxSQ6kCTZ/Dbw/yVk0/3ecSjMQ+R+B45KcC/zfdjsz9WXgj4EzaXpcXldVv07y/wA/ohlL8wDgZODLVXVLkh8D/wVcBPzHuPXt2NZ7PfCcLajjGOCsJBuq6tCquiHJycBV7eGziXyL5rDZHU4Hr6qrknyEJnT8ut2XybyE5k7XtwCnAFe30yf7jM8Cbk5yJvCJdhzOauDrW7C/Uud4N3FJmkYb/DbQDMD+2STz7Au8tqqeN8ttLamqze3zNwC7VtVEZ21Ntvy2NMHo0VV102xqkRYyD1FJ0hTSXPzvfOCkycINQFVtoBlEvdUsN/mU9pTvc2jOhHrrFi5/H+ANhhstdvbgSJKkzrEHR5IkdY4BR5IkdY4BR5IkdY4BR5IkdY4BR5Ikdc7/Dxw6me0aP1h6AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'predictions' is a NumPy array from model.predict(test_ds)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(predictions.flatten(), bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Prediction Probability Distribution')\n",
    "plt.xlabel('Predicted Probability (Target)')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
